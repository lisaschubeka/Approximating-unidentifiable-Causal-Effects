{
 "cells": [
  {
   "cell_type": "code",
   "id": "5cc0fbe7-dc61-4749-b397-3d539e8d05fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T09:50:41.879029Z",
     "start_time": "2024-05-23T09:50:41.442546Z"
    }
   },
   "source": [
    "# load autobounds components used in this demo\n",
    "from autobounds.causalProblem import causalProblem\n",
    "from autobounds.DAG import DAG\n",
    "from autobounds.Query import Query\n",
    "\n",
    "# load additional dependencies\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "import plotnine as pn\n",
    "\n",
    "# configure plotting options\n",
    "pn.options.figure_size = (8, 4)"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'canonicalModel'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# load autobounds components used in this demo\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mautobounds\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcausalProblem\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m causalProblem\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mautobounds\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mDAG\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DAG\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mautobounds\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mQuery\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Query\n",
      "File \u001B[0;32m~/Documents/TUM/Semester6/thesis/non_continous/autobounds-main/autobounds/causalProblem.py:1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mcanonicalModel\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m canonicalModel\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mQuery\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Query\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mProgram\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Program\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'canonicalModel'"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "e372cd1c-2bb8-46ed-9d59-8ce782380117",
   "metadata": {},
   "source": [
    "# Estimating treatment effects under post-treatment selection: <br>An introduction to `autobounds`\n",
    "\n",
    "Kai Cooper, Guilherme Duarte, and Dean Knox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157e97d2-782d-4db2-b954-6878cd2dc71d",
   "metadata": {},
   "source": [
    "This notebook introduces `autobounds` (Duarte et al., 2023), a method for automatically drawing principled inferences in the presence of common imperfections in data and design. It illustrates how `autobounds` can be used to obtain sharp bounds—the narrowest possible range of conclusions consistent with available, imperfect information—by extending Knox, Lowe, and Mummolo (2020)'s analysis of racial bias in New York Police Department (NYPD) use of force.\n",
    "\n",
    "- Section 1 introduces the empirical analysis of policing and its inherent selection issues, the running example in this notebook.\n",
    "- Section 2 states the causal effects of interest to the analyst and describes various assumptions that analysts might use.\n",
    "- Section 3 shows how to use `autobounds` to compute sharp bounds and probe sensitivity to assumptions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126a128c-61a1-4573-bb3a-3ac3140c3ddc",
   "metadata": {},
   "source": [
    "# 1. Design and data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294c7a20-84ce-4a26-b9c5-f28b60c8726c",
   "metadata": {},
   "source": [
    "Knox, Lowe, and Mummolo (2020) analyzes the use of force by NYPD officers in \"stop, question, and frisk\" encounters from 2003 to 2013, revisiting a prior analysis in Fryer (2019). The key question is whether minority civilians are subject to racial bias in the decision to use force.\n",
    "\n",
    "For the purposes of this illustration, we will focus on one of many analyses in the paper: whether white ($D=0$) and black ($D=1$) civilians are subject to different amounts of force. For clarity of exposition, we will omit additional covariates on civilian gender, age, behavior, time, location, and so on. As the paper shows, conclusions remain substantively similar when adjusting for this information—more often than not, the addition of controls slightly strengthens the estimated disparities. In this exercise, we will define the outcome $Y=0$ to mean the use of no force and $Y=1$ as an officer's decision to use any amount of force, from the laying of hands on a civilian to more severe acts like the use of a baton or pepper spray. A variety of force thresholds are examined in the original paper.\n",
    "\n",
    "The central methodological challenge identified in the paper is that analyses of police administrative stop records must inherently condition on the existence of a stop record, which depends on an officer's often-discretionary decision to initiate the stop, denoted $M$. \n",
    "In other words, every row in the data represents an police-civilian encounter in which a stop that was made ($M=1$), but encounters in which no stop was made ($M=0$) do not appear in the data. In fact, analysts do not even have information about the number of these non-stop encounters.\n",
    "\n",
    "This stopping decision may itself be discriminatory, i.e. depend on civilian race. Moreover, this stopping decision also affects the use of force, because officers typically do not use force on civilians that they do not first detain. $M$ is therefore a mediator between the treatment $D$ and outcome $Y$. Therefore, the data is selected on a post-treatment variable that also mediates the effect of treatment. The paper argues that unobserved factors, $U$, are likely to jointly influence officers decisions to stop and use force. The theorized causal graph is shown below.\n",
    "\n",
    "![image](images/klm_dag.png)\n",
    "\n",
    "Next, we will present some exploratory analyses to introduce the data and design."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de961c7",
   "metadata": {},
   "source": [
    "## 1.a. Load and inspect raw data\n",
    "\n",
    "In this subsection, we will import the data and examine some summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "id": "893cd4da-60a3-47b6-8419-73526104f15c",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "data = pd.read_csv(\"data/klm_demo_bw_anyforce.csv\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ed8b7e30",
   "metadata": {},
   "source": [
    "# 2,874,532 rows x 3 columns\n",
    "data.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c77c5f48-842c-42a1-9f95-7bfe0d4ebc4b",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# examine random sample\n",
    "data.sample(5)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2316aa30",
   "metadata": {},
   "source": [
    "# examine \n",
    "data.mean()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ebed919f",
   "metadata": {},
   "source": [
    "That is, 100% of encounters in the dataset involved a stop, due to the inherently selected nature of police administrative data. Of these stops, 86% were of Black civilians. Police officers used at least some force in 21% of all stops."
   ]
  },
  {
   "cell_type": "code",
   "id": "0d5c04f0-8ed9-4f18-888d-56afc54668a1",
   "metadata": {},
   "source": [
    "# count number of units with each combination of D, M, Y\n",
    "(\n",
    "    data\n",
    "    .value_counts()\n",
    "    .sort_values()    \n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5cb16e56",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# generate informative variable names for plotting\n",
    "data = data.assign(\n",
    "    D_label = data.D.map({0 : \"black civ\", 1 : \"white civ\"}),\n",
    "    M_label = data.M.map({0 : \"not stopped\", 1 : \"stopped\"}),\n",
    "    Y_label = data.Y.map({0 : \"no force used\", 1 : \"at least some force used\"})\n",
    ")\n",
    "\n",
    "# create initial visualization\n",
    "(\n",
    "    pn.ggplot(data,\n",
    "              pn.aes(x = \"D_label\",\n",
    "                     fill = \"Y_label\"\n",
    "                    )\n",
    "             ) \n",
    "    + pn.facet_wrap(\"M_label\")\n",
    "    + pn.geom_histogram(binwidth = 1, position = 'dodge')\n",
    "    + pn.ylab(\"Frequency\")\n",
    "    + pn.theme_light()\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b89eea23",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e725fbc7",
   "metadata": {},
   "source": [
    "## 1.b. Conduct preliminary analyses\n",
    "\n",
    "In this subsection, we will conduct a preliminary regression analysis that blindly ignores the presence of selection. This is the approach used in Fryer (2019)."
   ]
  },
  {
   "cell_type": "code",
   "id": "31bb2ded-805b-4f41-b618-cb6eb3b34a20",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# regression that blindly ignores selection \n",
    "model = smf.ols(\"Y ~ D\", data = data).fit()\n",
    "model.summary()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "bd5a3a0b-6d35-411b-820d-049d32a2b0c6",
   "metadata": {},
   "source": [
    "This regression suggests that, conditional on selection into the dataset, that black civilians are subject to slightly higher rates of force. However, a na&iuml;ve regression suggests that the difference is relatively small, roughly 6 percentage points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c84da05-f2c9-47c1-9d3f-b2594f0a734f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68d5dbe-6be3-47e3-ba63-ed13ea5d2241",
   "metadata": {},
   "source": [
    "## 1.c. Prepare summary statistics\n",
    "\n",
    "Finally, we will preprocess the data. `autobounds` works with sufficient statistics that represent the proportion of units with each unique combination of values, so we will first compute these."
   ]
  },
  {
   "cell_type": "code",
   "id": "9b7a8a31",
   "metadata": {},
   "source": [
    "# count units with each unique combination of Z, X, Y \n",
    "data_summary = (\n",
    "    data\n",
    "    .loc[:, ['D', 'M', 'Y']]\n",
    "    .value_counts()\n",
    "    .rename('counts')\n",
    "    .reset_index()\n",
    ")\n",
    "data_summary"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b12e914b",
   "metadata": {},
   "source": [
    "# divide by the total to get the estimated probability of each type\n",
    "data_summary = data_summary.assign(prob = data_summary.counts / data_summary.counts.sum())\n",
    "data_summary"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "90d1266f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179c5009-0c5f-4eeb-b3c0-bc004ffb9c75",
   "metadata": {},
   "source": [
    "# 2. Background, assumptions, and estimands\n",
    "\n",
    "In this section, we provide brief background on the instrumental variables model, as well as a discussion of common assumptions and estimands."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88983d3",
   "metadata": {},
   "source": [
    "## 2.a. Possible assumptions in analyzing police use of force\n",
    "\n",
    "Knox, Lowe, and Mummolo (2020) discusses a number of assumptions that may be employed in the substantive context of police stops.\n",
    "\n",
    "- **Mandatory reporting:** A plausible assumption is that all uses of force are reported on stop forms. This implies that if officers do not initiate a stop, then they do not go on to use force. Formally, $Y(D=d, M=0) = 0$ for all civilian races $d \\in \\{0, 1\\}$.\n",
    "- **Mediator monotonicity:** If officers discriminate in their stopping decisions, it is likely to be against black civilians. In other words, this assumption states that there is no anti-white discriminatory stopping. Later, we will show how to relax this assumption. Formally, $M(D=1) \\ge M(D=0)$.\n",
    "- **Relative nonseverity of racial stops:** If officers would make different stopping decisions depending on civilian race, so that $M(D=0) \\ne M(D=1)$ while holding all else equal, then the stop is by definition discretionary. In contrast, \"always stop\" encounters are those with $M(D=0) = M(D=1) = 1$. We cannot directly identify which encounters are of which types, but it is assumed that discretionary racial-stop encounters are less severe than always-stop encounters, in the sense that that officers would use less force on average (holding civilian race and stopping decisions fixed) in racial-stop encounters compared to always-stop encounters. Formally,\n",
    "$\\mathbb{E}[ Y(d, m) | \\text{racial stop}] \\le \\mathbb{E}[ Y(d, m) | \\text{always stop}]$.\n",
    "- **Treatment ignorability:** Civilian race is \"as good as randomly assigned\" to encounters after adjusting for covariates (if any are used). Equivalently, black and white civilians appear in circumstances that are objectively no different. This is a structural causal assumption that is encoded in the unconfoundedness of $D$ in the causal graph. As the paper notes, \"every study claiming to estimate racial discrimination using similar data makes this assumption, often implicitly. Our aim in this study is not to assert the plausibility of treatment ignorability, but rather to clarify that deep problems remain even if this well-known issue is somehow solved.\"\n",
    "\n",
    "Next, the paper points out additional, implausible assumptions that prior work such as Fryer (2019) has used, often implicitly:\n",
    "- **Mediator ignorability:** This states that officer stopping decisions are \"as good as randomly assigned\" after accounting for civilian race. Equivalently, it requires that there are no unobserved factors that jointly influence decisions to stop and use force (depicted as $U$ in the graph given in Figure 1). This is a structural assumption that rules out confounding of $M$. It makes little sense in the analysis of policing data, because numerous variables such as officer mental state are not recorded.\n",
    "- **No racial stops:** This states that officers do not discriminate in the decision to stop. It is a structural assumption that rules out the existence of a $D \\to M$ arrow in the graph. In a study of discrimination in one stage of policing (the decision to use force), it makes little sense to assume away discrimination im another stage (the decision to stop).\n",
    "\n",
    "If either the mediator-ignorability or no-racial-stops assumptions are satisfied, then the common approach of running regressions that ignore selection will produce unbiased estimates of one particular causal estimand, discussed below. However, for the reasons identified, these are unlikely to hold in the context of policing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b13bca1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fb4395",
   "metadata": {},
   "source": [
    "## 2.b. Implicit estimands in analyses of police stop data\n",
    "\n",
    "Researchers studying discrimination in police violence are interested in estimating an effect of civilian race, $D$, on police use of force, $Y$. However, in a detailed review of the literature, Knox, Lowe, and Mummolo (2020) identified no papers that explicitly identified the precise quantity of interest. Rather, the typical approach is to simply run a regression and informally gesture in the direction of a conclusion.\n",
    "\n",
    "To formalize research objectives and assess whether commonly used methods are capable of achieving these objectives with selected data, Knox, Lowe, and Mummolo (2020) discuss a number of possible estimands that prior work may have targeted:\n",
    "- **Average treatment effect** ($ATE$): The extent to which civilians of color face greater risk of police violence than white civilians because of their race, across all police-civilian encounters. This is a \"total effect\" that captures two related phenomena: first, whether members of the minority are differentially stopped; and second, if they are differentially subject to violence. A key challenge is that analysts do not know the proportion of this full population, all encounters, that are represented in the available data. Formally, it is $\\mathbb{E}[Y(D=1, M(D=1)) - Y(D=0, M(D=0))]$.\n",
    "- **Average treatment effect among the stopped** ($ATE_{M=1}$): The total effect *among the subgroup of encounters that appear in the data*. Conceptually, this involves \"cross-world\" reasoning in which analysts first identify the subgroup of interest using the real world, in terms of how officers made stopping decisions based on civilians' actual race. Then, analysts ask what the effect would be if the subgroup of interest were transported to an alternate world in which white or black civilians were randomized into these encounters, behaving in the same way. It is \"cross world\" because the subgroup of interest cannot be identified in the same world as the experiment. Despite this conceptual challenge, Knox, Lowe, and Mummolo (2020) concludes that this is the estimand most closely corresponding to how research is motivated and conclusions are interpreted in this literature. Formally, it is $\\mathbb{E}[Y(D=1, M(D=1)) - Y(D=0, M(D=0)) | M=1]$.\n",
    "- **Average treatment effect among the stopped and treated** ($ATT_{M=1}$): The total effect *among the subgroup of minority encounters that appear in the data*. This is analogous to the prior estimand, except that it excludes encounters with white civilians. Formally, it is $\\mathbb{E}[Y(D=1, M(D=1)) - Y(D=0, M(D=0)) | D=1, M=1]$.\n",
    "- **Controlled direct effect among the stopped** ($CDE_{M=1}$): This estimand differs from the $ATE_{M=1}$ in its conceptual approach to racially discriminatory stops. Where the $ATE_{M=1}$ asks whether a stop would have occurred at all if the individual were of differing race, the $CDE_{M=1}$ seeks to quantify what would have happened if the officer was forced to stop them anyway, perhaps against the officer's will. Formally, it is $\\mathbb{E}[Y(D=1, M=1) - Y(D=0, M=1) | M=1]$.\n",
    "\n",
    "Knox, Lowe, and Mummolo (2020) examine each of these estimands in turn and show that standard regressions using selected police data fail to recover any of them. In this demonstration, we will focus on bounds for the $ATE_{M=1}$, the formal estimand that most closely resembles the informal interpretation of prior results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174dc96d-6fc5-426a-b798-86b841248917",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577c267b-c52b-4816-9d98-c02b6a6b80fd",
   "metadata": {},
   "source": [
    "# 3. Bounding the $ATE_{M=1}$ under plausible assumptions with `autobounds`\n",
    "\n",
    "In this section, we demonstrate the use of `autobounds` by computing sharp bounds on the $ATE_{M=1}$ using the same assumptions used by Knox, Lowe, and Mummolo (2020). In that paper, bounds were obtained analytically, taking roughly 10 weeks of manual algebraic manipulation to derived and 15 pages of appendices to present.\n",
    "\n",
    "To do the same with `autobounds`, we will simply state each piece of the causal-inference problem we would like to solve. A problem is defined by five elements:\n",
    "- The causal graph, or structural assumptions relating the variables\n",
    "- The sample space, or the number of unique values that each variable can take on\n",
    "- Additional functional-form assumptions justified by domain expertise\n",
    "- The empirical evidence, or the data\n",
    "- The quantity of interest, or the estimand\n",
    "\n",
    "The following subsections present code for each of these in turn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0e22df-f0a5-4050-be46-b1390536735d",
   "metadata": {},
   "source": [
    "## 3.a. Defining the causal graph\n",
    "\n",
    "In this section, we will present a step-by-step demonstration of `autobounds`. As a working example, we will compute sharp bounds on the $ATE_{M=1}$ under the mandatory reporting, mediator monotonicity, relative nonseverity, and treatment ignorability assumptions. Later, we will show how these assumptions can be relaxed.\n",
    "\n",
    "First, we will define the assumed directed acyclic graph (DAG). All of the plausible assumptions in this case are structural assumptions that can be represented in this graph. Instatiate an empty DAG via the `DAG` class within the package. Build the structure of the graph with the method `.from_structure()`, which takes two arguments: \n",
    "- `edges`: A comma-separated string listing pairs of connected nodes. E.g. `\"A -> B, B -> C, U -> A, U -> B\"`\n",
    "- `unob`: A comma-separated string listing the nodes that are unobserved disturbances\n",
    "\n",
    "The graph can then be visualized using its `.plot()` method."
   ]
  },
  {
   "cell_type": "code",
   "id": "0350effe",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# first initialize an empty graph\n",
    "graph = DAG()\n",
    "\n",
    "# define edges and unobserved disturbances\n",
    "graph.from_structure(\n",
    "    edges = \"Ud -> D, D -> M, D -> Y, M -> Y, Umy -> M, Umy -> Y\",\n",
    "    unob = \"Ud, Umy\"\n",
    ")\n",
    "\n",
    "# visualize the graph\n",
    "graph.plot()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2c675d9d",
   "metadata": {},
   "source": [
    "We will begin with the `causalProblem()` constructor, which takes two arguments:\n",
    "- `graph`: the causal structure that the problem involves\n",
    "- `number_values` (optional): a dictionary in which keys are variable names and values are variable cardinalities (binary, ternary, etc.). E.g. `\"{A : 2, B: 3}`. If left unspecified, all variables are assumed to be binary."
   ]
  },
  {
   "cell_type": "code",
   "id": "32ebc904",
   "metadata": {},
   "source": [
    "# initialize a causal-inference problem involving the klm dag\n",
    "problem = causalProblem(\n",
    "    graph,\n",
    "    number_values = {\"D\" : 2, \"M\" : 2, \"Y\" : 2}  # for illustration (not needed, same as defaults)\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "05dce9b7",
   "metadata": {},
   "source": [
    "After initializing this problem, we next add the assumptions that `autobounds` should use.\n",
    "\n",
    "Here, we will introduce the functional assumptions (mandatory reporting, mediator monotonicity, and relative nonseverity) using the `.add_constraint()` method. The fourth assumption, treatment ignorability, is a structural assumption that is already encoded in the causal graph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d6b18c-c5ae-4bb0-9c32-14c8545ccca5",
   "metadata": {},
   "source": [
    "We will begin with the mandatory reporting assumption, which can be stated nearly verbatim."
   ]
  },
  {
   "cell_type": "code",
   "id": "84c111ad",
   "metadata": {},
   "source": [
    "# assumption 1: if no stop is made, no force is used\n",
    "force_used_without_stop = problem.query('Y(M=0)=1')    # define the group\n",
    "problem.add_constraint(force_used_without_stop, '==')  # constrain group size (defaults to 0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "089b59f7-0dea-44d3-b686-7b0a55742901",
   "metadata": {},
   "source": [
    "Next, we incorporate the mediator monotonicity assumption, which is also straightforward."
   ]
  },
  {
   "cell_type": "code",
   "id": "a81fc8ab-bdab-4852-bc13-d7113d708265",
   "metadata": {},
   "source": [
    "# assumption 2: if officers discriminate in stopping at all, it is likely against black civilians\n",
    "anti_white_stop = problem.query(\"M(D=0)=1 & M(D=1)=0\")  # define the group\n",
    "problem.add_constraint(anti_white_stop, '==')           # constrain group size (defaults to 0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6cdf5187-b397-4296-9d8a-3b21a716cdc2",
   "metadata": {},
   "source": [
    "The nonseverity assumption is more complex for two reasons:\n",
    "1. it is assumed to hold for all $d \\in \\{0, 1\\}$ and all $m \\in \\{0, 1\\}$, meaning it is composed of separate assumptions for each combination of $d$ and $m$ and must be stated in a loop; and\n",
    "2. it involves inequality statements about conditional probabilities, which will be easier when some planned functionalities are implemented, but currently requires a slight workaround."
   ]
  },
  {
   "cell_type": "code",
   "id": "bdbf6759-04bf-4bec-b96c-2d71da2f624b",
   "metadata": {},
   "source": [
    "# assumption 3: \n",
    "\n",
    "# define groups (anti-white stops are defined above)\n",
    "always_stop = problem.query(\"M(D=0)=1 & M(D=1)=1\")\n",
    "anti_black_stop = problem.query(\"M(D=0)=0 & M(D=1)=1\")\n",
    "\n",
    "# for all d and m\n",
    "for d in [0, 1]:\n",
    "    for m in [0, 1]:\n",
    "        \n",
    "        # Pr[ force would counterfactually be used under this d and m AND encounter belongs to this group ]\n",
    "        potential_force_dm_and_always_stop = problem.query(\"Y(D={d},M={m})=1 & M(D=0)=1 & M(D=1)=1\".format(d=d, m=m))\n",
    "        potential_force_dm_and_anti_black_stop = problem.query(\"Y(D={d},M={m})=1 & M(D=0)=0 & M(D=1)=1\".format(d=d, m=m))\n",
    "        potential_force_dm_and_anti_white_stop = problem.query(\"Y(D={d},M={m})=1 & M(D=0)=1 & M(D=1)=0\".format(d=d, m=m))\n",
    "\n",
    "        # # by Bayes' rule:\n",
    "        # # Pr[ force would counterfactually be used under this d and m | encounter belongs to this group ]\n",
    "        # # == Pr[ force would counterfactually be used under this d and m AND encounter belongs to this group ] /\n",
    "        # #    Pr[ encounter belongs to this group ]\n",
    "        # potential_force_dm_cond_always_stop = potential_force_dm_and_always_stop / always_stop\n",
    "        # potential_force_dm_cond_anti_black_stop = potential_force_dm_and_anti_black_stop / anti_black_stop\n",
    "        # potential_force_dm_cond_anti_white_stop = potential_force_dm_and_anti_white_stop / anti_white_stop\n",
    "        # # this uses functionality that has not yet been implemented: division operator will be available in a future version\n",
    "        #        \n",
    "        # # assumption 3 as stated:\n",
    "        # problem.add_constraint(potential_force_dm_cond_anti_black_stop, \"<=\", potential_force_dm_cond_always_stop)\n",
    "        # problem.add_constraint(potential_force_dm_cond_anti_white_stop, \"<=\", potential_force_dm_cond_always_stop)\n",
    "        # # this uses functionality that has not yet been implemented: right-hand-side variables will be available in a future version\n",
    "\n",
    "        # using functionality that is currently available, the following is an equivalent but slightly more clunky workaround\n",
    "        problem.add_constraint(\n",
    "            potential_force_dm_and_anti_black_stop * always_stop - potential_force_dm_and_always_stop * anti_black_stop,\n",
    "            \"<=\" \n",
    "            # defaults to 0\n",
    "        )\n",
    "        problem.add_constraint(\n",
    "            potential_force_dm_and_anti_white_stop * always_stop - potential_force_dm_and_always_stop * anti_white_stop,\n",
    "            \"<=\" \n",
    "            # defaults to 0\n",
    "        )\n",
    "        # this is equivalent because\n",
    "        #   potential_force_dm_and_anti_xxx_stop / anti_xxx_stop <= potential_force_dm_and_always_stop / always_stop\n",
    "        #   is equivalent to potential_force_dm_and_anti_x_stop * always_stop <= potential_force_dm_and_always_stop * anti_x_stop\n",
    "        #   is equivalent to potential_force_dm_and_anti_x_stop * always_stop - potential_force_dm_and_always_stop * anti_x_stop <= 0"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b2f8e5a2-ee8e-4730-b275-9b5509cfb002",
   "metadata": {},
   "source": [
    "In addition to these assumptions based on substantive knowledge of a problem, analysts may wish to incorporate side information based on previous research. For example, previous work by Gelman, Fagan, and Kiss (2007) implies that among black stops, at least 32% of black stops were racially discriminatory. This can be easily incorporated as an additional constraint."
   ]
  },
  {
   "cell_type": "code",
   "id": "5b2bca58-8b0f-4bdc-815d-e6d32e8a5357",
   "metadata": {},
   "source": [
    "# incorporating side information: proportion of black stops that would not have been made if white\n",
    "black_and_stop = problem.query(\"D=1 & M=1\")\n",
    "black_and_stop_and_discriminatory = problem.query(\"D=1 & M=1 & M(D=0)=0\")\n",
    "lower_bound_on_prop_black_stops_discriminatory_gfk07 = Query(0.32)\n",
    "\n",
    "# # by Bayes' rule:\n",
    "# # Pr[ would not stop if white | black AND stopped ]\n",
    "# # == Pr[ black AND stopped AND would not stop if white ] / Pr[ black AND stopped ]\n",
    "# discriminatory_cond_black_and_stop = black_and_stop_and_discriminatory / black_and_stop\n",
    "# # this uses functionality that has not yet been implemented: division operator will be available in a future version\n",
    "#\n",
    "# incorporating the side information:\n",
    "# problem.add_constraint(discriminatory_cond_black_and_stop, \">=\", lower_bound_on_prop_black_stops_discriminatory_gfk07) \n",
    "# # this uses functionality that has not yet been implemented: right-hand-side variables will be available in a future version\n",
    "\n",
    "# using functionality that is currently available, the following is an equivalent but slightly more clunky workaround\n",
    "problem.add_constraint(\n",
    "    black_and_stop_and_discriminatory - \n",
    "    lower_bound_on_prop_black_stops_discriminatory_gfk07 * black_and_stop,\n",
    "    \">=\"\n",
    "    # defaults to 0\n",
    ")\n",
    "# this is equivalent because\n",
    "#   black_and_stop_and_discriminatory / black_and_stop >= 0.32\n",
    "#   is equivalent to black_and_stop_and_discriminatory >= 0.32 * black_and_stop\n",
    "#   is equivalent to black_and_stop_and_discriminatory - 0.32 * black_and_stop >= 0"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "aa7fc867-6d0d-4cf9-b8a3-09845caf3435",
   "metadata": {},
   "source": [
    "Currently, we also need to tell `autobounds` about the laws of probability. This is done with the `.add_prob_constraints()` method, but will be automated in the next update."
   ]
  },
  {
   "cell_type": "code",
   "id": "0e70a1a9-b2fb-41ce-862f-8b045a113aef",
   "metadata": {},
   "source": [
    "# tell autobounds about the laws of probability\n",
    "# (in a future update this will be handled automatically)\n",
    "problem.add_prob_constraints()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "bb4f1a4e",
   "metadata": {},
   "source": [
    "The second to last step is to tell `autobounds` about the empirical evidence. The `.load_data()` method accepts summary statistics in the form of a `pandas` `DataFrame` object or a path to a CSV file. It accepts a second, optional argument, `cond`, containing a list of the variables on which the data are conditioned. In this case, all summary statistics are conditional on $M$ (specifically, $M=1$), so the argument `cond = [\"M\"]` is supplied.\n",
    "\n",
    "Regardless of the input format, this must contain (i) one column per variable measured in the dataset, (ii) one row per unique combination of values, and (iii) an additional column named \"prob\" indicating the proportion of units of this type. An example is given in `data_summary` above."
   ]
  },
  {
   "cell_type": "code",
   "id": "00cac31d",
   "metadata": {},
   "source": [
    "# load in the data\n",
    "problem.load_data(data_summary, cond = [\"M\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "deeb21e5",
   "metadata": {},
   "source": [
    "The last step is to define the quantity of interest: the ATE of race ($D$) on use of force ($Y$), conditional on a stop having been made ($M=1$). Below, three arguments are provided to the `.set_ate()` method:\n",
    "- `ind`: the name of the independent variable, or treatment\n",
    "- `dep`: the name of the dependent variable, or outcome\n",
    "- `cond`: the subgroup of interest, identified through a separate `.query()` of the problem"
   ]
  },
  {
   "cell_type": "code",
   "id": "54a5c3a9",
   "metadata": {},
   "source": [
    "# for numerical stability, currently we need to add a constraint that the subgroup of interest has nonzero size\n",
    "# this will be made automatic in a future version\n",
    "stop = problem.query(\"M=1\")\n",
    "small_positive_number = Query(.01)\n",
    "problem.add_constraint(stop - small_positive_number, \">=\")  # defaults to 0\n",
    "\n",
    "problem.set_ate(ind = \"D\", dep = \"Y\", cond = \"M=1\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "26c59a0e-1a16-4da5-903e-e4ab318cc613",
   "metadata": {},
   "source": [
    "Finally, we are ready to compute bounds. To do so, we will first translate the completely specified causal-inference problem into an equivalent *optimization program*. Solving this program with a numeric optimizer (like SCIP in the example below) will produce the desired sharp bounds."
   ]
  },
  {
   "cell_type": "code",
   "id": "3f27ac5b-c823-455b-8a87-9f4fbb7bb5ee",
   "metadata": {},
   "source": [
    "# translate causal inference problem into optimization program\n",
    "program = problem.write_program()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c8092c41-c147-40b4-a740-04eaecb473ba",
   "metadata": {},
   "source": [
    "program.to_pip('klm_baseline.pip')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d712cdce-8049-40ae-b489-902a064ab663",
   "metadata": {},
   "source": [
    "# to speed up demo, stop early before bounds are completely sharp (which would be epsilon = 0)\n",
    "# with verbose = True, autobounds will periodically report progress on \n",
    "# - upper and lower bounding problems (the \"dual\" bounds are the guaranteed-valid causal bounds)\n",
    "# - width of the guaranteed-valid causal bounds (theta = upper bound - lower bound)\n",
    "# - proportion of those bounds that might be narrowed with further computation (epsilon)\n",
    "results = program.run_scip(verbose = True, epsilon = .1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "51252d27-96ca-4be0-9948-73b9ff076fe0",
   "metadata": {},
   "source": [
    "\"Based on these data and assumptions, the ATE_(M=1) is in the range [{lower:0.3f}, {upper:0.3f}]\".format(\n",
    "    lower = results[0][\"dual\"],  # index [0] selects lower bound, key [\"dual\"] selects guaranteed-valid bound\n",
    "    upper = results[1][\"dual\"],  # index [1] selects upper bound, key [\"dual\"] selects guaranteed-valid bound\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "df71409e-8472-4b57-86f4-c0d0a6d35249",
   "metadata": {},
   "source": [
    "In other words, based on assumptions that are highly plausible, analysts can determine that the effect of the treatment is strongly positive, despite the issues noted. Moreover, it is larger than the 0.061 value suggested by the na&iuml;ve regression that ignored selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0638da57-389e-4d22-8c5e-eb6d27627771",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf28f60-c928-488c-b97d-4fb64ddc829b",
   "metadata": {},
   "source": [
    "## 4. Probing assumptions to examining sensitivity of conclusions\n",
    "\n",
    "What if we would like to understand which assumptions drive the substantive conclusion? With `autobounds`, it is straightforward to conduct an \"ablation\" analysis that removes one assumption at a time, then recomputes the bounds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac34f97b-ea34-4357-8625-746dddd4a070",
   "metadata": {},
   "source": [
    "### 4.a. Removing the relative nonseverity assumption\n",
    "\n",
    "We will begin by eliminating the relative nonseverity assumption. To do so, we simply define a causal problem exactly as above, but omit the statement of these constraints."
   ]
  },
  {
   "cell_type": "code",
   "id": "aca5a8a8-d008-4d92-a352-90d17766ec19",
   "metadata": {},
   "source": [
    "# initialize a causal-inference problem involving the klm dag\n",
    "problem_drop_nonseverity = causalProblem(graph)\n",
    "\n",
    "# assumption 1: if no stop is made, no force is used\n",
    "problem_drop_nonseverity.add_constraint(force_used_without_stop, '==')  # constrain group size (defaults to 0)\n",
    "\n",
    "# assumption 2: if officers discriminate in stopping at all, it is likely against black civilians\n",
    "problem_drop_nonseverity.add_constraint(anti_white_stop, '==')           # constrain group size (defaults to 0)\n",
    "\n",
    "# assumption 3: removed\n",
    "\n",
    "# side information from gelman, fagan, and kiss (2007)\n",
    "problem_drop_nonseverity.add_constraint(\n",
    "    black_and_stop_and_discriminatory - \n",
    "    lower_bound_on_prop_black_stops_discriminatory_gfk07 * black_and_stop,\n",
    "    \">=\"\n",
    "    # defaults to 0\n",
    ")\n",
    "\n",
    "# tell autobounds about the laws of probability (this will be made automatic in a future update)\n",
    "problem_drop_nonseverity.add_prob_constraints()\n",
    "\n",
    "# load in the data\n",
    "problem_drop_nonseverity.load_data(data_summary, cond = [\"M\"])\n",
    "\n",
    "# define the estimand (for numerical stability, currently we need to add a constraint that the subgroup of interest has nonzero size)\n",
    "stop = problem_drop_nonseverity.query(\"M=1\")\n",
    "small_positive_number = Query(.01)\n",
    "problem_drop_nonseverity.add_constraint(stop - small_positive_number, \">=\")  # defaults to 0\n",
    "problem_drop_nonseverity.set_ate(ind = \"D\", dep = \"Y\", cond = \"M=1\")\n",
    "\n",
    "# translate causal inference problem into optimization program\n",
    "program_drop_nonseverity = problem_drop_nonseverity.write_program()\n",
    "\n",
    "# compute bounds\n",
    "results_drop_nonseverity = program_drop_nonseverity.run_scip(verbose = True, epsilon = .1)\n",
    "\n",
    "\"Without the relative nonseverity assumption, we would conclude the ATE_(M=1) is in the range [{lower:0.3f}, {upper:0.3f}]\".format(\n",
    "    lower = results_drop_nonseverity[0][\"dual\"],  # index [0] selects lower bound, key [\"dual\"] selects guaranteed-valid bound\n",
    "    upper = results_drop_nonseverity[1][\"dual\"],  # index [1] selects upper bound, key [\"dual\"] selects guaranteed-valid bound\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2c6da98f-f152-45e8-b16b-79fbbd555205",
   "metadata": {},
   "source": [
    "The bounds have not changed much, suggesting that the relative nonseverity assumption is not a major driver of these conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e000efca-ef6e-4c0e-a062-0a5a4277e6a5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3a88c4-86bd-4a18-9343-449763ca321a",
   "metadata": {},
   "source": [
    "### 4.b. Removing the mediator monotonicity assumption\n",
    "\n",
    "Next, we will reinstate relative nonseverity and eliminate mediator monotonicity to see if this assumption is more impactful."
   ]
  },
  {
   "cell_type": "code",
   "id": "d0ecba03-5bd8-4ac6-9574-e54a6da17dd5",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# initialize a causal-inference problem involving the klm dag\n",
    "problem_drop_monotonicity = causalProblem(graph)\n",
    "\n",
    "# assumption 1: if no stop is made, no force is used\n",
    "problem_drop_monotonicity.add_constraint(force_used_without_stop, '==')  # constrain group size (defaults to 0)\n",
    "\n",
    "# assumption 2: removed\n",
    "\n",
    "# assumption 3: \n",
    "for d in [0, 1]:\n",
    "    for m in [0, 1]:        \n",
    "        # Pr[ force would counterfactually be used under this d and m AND encounter belongs to this group ]\n",
    "        potential_force_dm_and_always_stop = problem_drop_monotonicity.query(\"Y(D={d},M={m})=1 & M(D=0)=1 & M(D=1)=1\".format(d=d, m=m))\n",
    "        potential_force_dm_and_anti_black_stop = problem_drop_monotonicity.query(\"Y(D={d},M={m})=1 & M(D=0)=0 & M(D=1)=1\".format(d=d, m=m))\n",
    "        potential_force_dm_and_anti_white_stop = problem_drop_monotonicity.query(\"Y(D={d},M={m})=1 & M(D=0)=1 & M(D=1)=0\".format(d=d, m=m))\n",
    "        problem_drop_monotonicity.add_constraint(\n",
    "            potential_force_dm_and_anti_black_stop * always_stop - potential_force_dm_and_always_stop * anti_black_stop,\n",
    "            \"<=\" \n",
    "            # defaults to 0\n",
    "        )\n",
    "        problem_drop_monotonicity.add_constraint(\n",
    "            potential_force_dm_and_anti_white_stop * always_stop - potential_force_dm_and_always_stop * anti_white_stop,\n",
    "            \"<=\" \n",
    "            # defaults to 0\n",
    "        )\n",
    "\n",
    "# side information from gelman, fagan, and kiss (2007)\n",
    "problem_drop_monotonicity.add_constraint(\n",
    "    black_and_stop_and_discriminatory - \n",
    "    lower_bound_on_prop_black_stops_discriminatory_gfk07 * black_and_stop,\n",
    "    \">=\"\n",
    "    # defaults to 0\n",
    ")\n",
    "\n",
    "# tell autobounds about the laws of probability (this will be made automatic in a future update)\n",
    "problem_drop_monotonicity.add_prob_constraints()\n",
    "\n",
    "# load in the data\n",
    "problem_drop_monotonicity.load_data(data_summary, cond = [\"M\"])\n",
    "\n",
    "# define the estimand (for numerical stability, currently we need to add a constraint that the subgroup of interest has nonzero size)\n",
    "stop = problem_drop_monotonicity.query(\"M=1\")\n",
    "small_positive_number = Query(.01)\n",
    "problem_drop_monotonicity.add_constraint(stop - small_positive_number, \">=\")  # defaults to 0\n",
    "problem_drop_monotonicity.set_ate(ind = \"D\", dep = \"Y\", cond = \"M=1\")\n",
    "\n",
    "# translate causal inference problem into optimization program\n",
    "program_drop_monotonicity = problem_drop_monotonicity.write_program()\n",
    "\n",
    "# compute bounds\n",
    "results_drop_monotonicity = program_drop_monotonicity.run_scip(verbose = True, epsilon = .1)\n",
    "\n",
    "\"Without the mediator monotonicity assumption, we would conclude the ATE_(M=1) is in the range [{lower:0.3f}, {upper:0.3f}]\".format(\n",
    "    lower = results_drop_monotonicity[0][\"dual\"],  # index [0] selects lower bound, key [\"dual\"] selects guaranteed-valid bound\n",
    "    upper = results_drop_monotonicity[1][\"dual\"],  # index [1] selects upper bound, key [\"dual\"] selects guaranteed-valid bound\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "230234f3-1179-44a0-bf02-bc589d8e15a1",
   "metadata": {},
   "source": [
    "These bounds are much wider, suggesting that mediator monotonicity is a highly impactful assumption. This means we should probe it carefully to evaluate whether it is as plausible as we initially believed, and also that we may want to evaluate the consequences for our claims if the assumption is violated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851962cd-4bd2-4f38-a913-e1caedbb4543",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7a4386-38fe-4cf0-9929-064c61ba16c0",
   "metadata": {},
   "source": [
    "### 4.c. Relaxing the mediator monotonicity assumption rather than removing it entirely\n",
    "\n",
    "Of course, we do not actually believe that there is potentially unlimited anti-white discrimination in NYPD stopping decisions. To assess how common this scenario might be, it is useful to consider how anti-white discrimination might arise. Gelman, Fagan, and Kiss (2007) discuss one possible source: that white civilians might be more likely to be stopped by police if they appear out of place in a predominantly black neighborhood, perhaps under the assumption that they were there to buy drugs. These kinds of stops are exceedingly rare, and other scenarios like them are likely also rare.\n",
    "\n",
    "Based on this consideration of the assumption, a reasonable relaxation of the assumption might be that anti-white stops may exist but are likely to represent no more than 5% of the NYPD's encounters with civilian. This alternative assumption can be incorporated into the causal problem in place of mediator monotonicity."
   ]
  },
  {
   "cell_type": "code",
   "id": "9f106e30-4946-41bd-86f2-15d09448cd89",
   "metadata": {},
   "source": [
    "# initialize a causal-inference problem involving the klm dag\n",
    "problem_relax_monotonicity = causalProblem(graph)\n",
    "\n",
    "# assumption 1: if no stop is made, no force is used\n",
    "problem_relax_monotonicity.add_constraint(force_used_without_stop, '==')  # constrain group size (defaults to 0)\n",
    "\n",
    "# assumption 2: if officers discriminate against white civilians in stopping, it is likely not by a large amount\n",
    "# currently, Pr(anti-white stops) <= .05 must be restated as Pr(anti-white stops) - .05 <= 0 (future updates will make this easier)\n",
    "problem_relax_monotonicity.add_constraint(anti_white_stop - Query(.05), '<=')\n",
    "\n",
    "# assumption 3: \n",
    "for d in [0, 1]:\n",
    "    for m in [0, 1]:        \n",
    "        # Pr[ force would counterfactually be used under this d and m AND encounter belongs to this group ]\n",
    "        potential_force_dm_and_always_stop = problem_relax_monotonicity.query(\"Y(D={d},M={m})=1 & M(D=0)=1 & M(D=1)=1\".format(d=d, m=m))\n",
    "        potential_force_dm_and_anti_black_stop = problem_relax_monotonicity.query(\"Y(D={d},M={m})=1 & M(D=0)=0 & M(D=1)=1\".format(d=d, m=m))\n",
    "        potential_force_dm_and_anti_white_stop = problem_relax_monotonicity.query(\"Y(D={d},M={m})=1 & M(D=0)=1 & M(D=1)=0\".format(d=d, m=m))\n",
    "        problem_relax_monotonicity.add_constraint(\n",
    "            potential_force_dm_and_anti_black_stop * always_stop - potential_force_dm_and_always_stop * anti_black_stop,\n",
    "            \"<=\" \n",
    "            # defaults to 0\n",
    "        )\n",
    "        problem_relax_monotonicity.add_constraint(\n",
    "            potential_force_dm_and_anti_white_stop * always_stop - potential_force_dm_and_always_stop * anti_white_stop,\n",
    "            \"<=\" \n",
    "            # defaults to 0\n",
    "        )\n",
    "\n",
    "# side information from gelman, fagan, and kiss (2007)\n",
    "problem_relax_monotonicity.add_constraint(\n",
    "    black_and_stop_and_discriminatory - \n",
    "    lower_bound_on_prop_black_stops_discriminatory_gfk07 * black_and_stop,\n",
    "    \">=\"\n",
    "    # defaults to 0\n",
    ")\n",
    "\n",
    "# tell autobounds about the laws of probability (this will be made automatic in a future update)\n",
    "problem_relax_monotonicity.add_prob_constraints()\n",
    "\n",
    "# load in the data\n",
    "problem_relax_monotonicity.load_data(data_summary, cond = [\"M\"])\n",
    "\n",
    "# define the estimand (for numerical stability, currently we need to add a constraint that the subgroup of interest has nonzero size)\n",
    "stop = problem_relax_monotonicity.query(\"M=1\")\n",
    "small_positive_number = Query(.01)\n",
    "problem_relax_monotonicity.add_constraint(stop - small_positive_number, \">=\")  # defaults to 0\n",
    "problem_relax_monotonicity.set_ate(ind = \"D\", dep = \"Y\", cond = \"M=1\")\n",
    "\n",
    "# translate causal inference problem into optimization program\n",
    "program_relax_monotonicity = problem_relax_monotonicity.write_program()\n",
    "\n",
    "# compute bounds\n",
    "results_relax_monotonicity = program_relax_monotonicity.run_scip(verbose = True, epsilon = .1)\n",
    "\n",
    "\"With this relaxation of the mediator monotonicity assumption, we would conclude the ATE_(M=1) is in the range [{lower:0.3f}, {upper:0.3f}]\".format(\n",
    "    lower = results_relax_monotonicity[0][\"dual\"],  # index [0] selects lower bound, key [\"dual\"] selects guaranteed-valid bound\n",
    "    upper = results_relax_monotonicity[1][\"dual\"],  # index [1] selects upper bound, key [\"dual\"] selects guaranteed-valid bound\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "11e2484b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1140b515",
   "metadata": {},
   "source": [
    "## 4.d. Visualizing sensitivity to assumptions\n",
    "\n",
    "Finally, we present a Manski-style analysis that probes the sensitivity of our conclusions to the assumptions that are made. `autobounds` allows this careful and transparent approach to be generalized to any causal analysis."
   ]
  },
  {
   "cell_type": "code",
   "id": "9bae16e9",
   "metadata": {},
   "source": [
    "bounds_under_varying_assumptions = pd.DataFrame(\n",
    "    [\n",
    "        {'assumption_set' : 'original analysis', \n",
    "         'lower_bound' : results[0][\"dual\"],\n",
    "         'upper_bound' : results[1][\"dual\"]\n",
    "        },\n",
    "        {'assumption_set' : 'dropping\\nnonseverity\\nof racial stops', \n",
    "         'lower_bound' : results_drop_nonseverity[0][\"dual\"],\n",
    "         'upper_bound' : results_drop_nonseverity[1][\"dual\"]\n",
    "        },\n",
    "        {'assumption_set' : 'dropping\\nmediator\\nmonotonicity', \n",
    "         'lower_bound' : results_drop_monotonicity[0][\"dual\"],\n",
    "         'upper_bound' : results_drop_monotonicity[1][\"dual\"]\n",
    "        },\n",
    "        {'assumption_set' : 'relaxing\\nmediator\\nmonotonicity', \n",
    "         'lower_bound' : results_relax_monotonicity[0][\"dual\"],\n",
    "         'upper_bound' : results_relax_monotonicity[1][\"dual\"]\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "bounds_under_varying_assumptions"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "602e1ec9",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5e8133ec-e90b-41bf-b686-fa4c4434303a",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc0c805-e181-4496-9941-e805b6aff656",
   "metadata": {},
   "source": [
    "Guilherme Duarte, Noam Finkelstein, Dean Knox, Jonathan Mummolo, and Ilya Shpitser. 2023. \"An Automated Approach to Causal Inference in Discrete Settings,\" *Journal of the American Statistical Association* (Theory and Methods). https://doi.org/10.1080/01621459.2023.2216909\n",
    "\n",
    "Andrew Gelman, Jeffrey Fagan, and Alex Kiss. 2007. \"An Analysis of the New York City Police Department's 'Stop-and-Frisk' Policy in the Context of Claims of Racial Bias.\" *Journal of the American Statistical Association* (Applications and Case Studies). https://doi.org/10.1198/016214506000001040\n",
    "\n",
    "Roland Fryer. 2019. \"An Empirical Analysis of Racial Differences in Police Use of Force.\" *Journal of Political Economy*. https://doi.org/10.1086/701423\n",
    "\n",
    "Dean Knox, Will Lowe, and Jonathan Mummolo. 2020. \"Administrative Records Mask Racially Biased Policing,\" *American Political Science Review*. https://doi.org/10.1017/S0003055420000039\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
